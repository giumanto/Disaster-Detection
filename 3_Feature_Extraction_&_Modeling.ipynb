{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:/Users/giuma/Dropbox/Web and Social media Analytics Project/\"\n",
    "\n",
    "do_FE = False # flag for the Feature Extraction process (set False when .pkl file can be imported)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14 ms\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_pickle(\"train_nlp_disaster.pkl\")\n",
    "df_test = pd.read_pickle(\"test_nlp_disaster.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>target_relabeled</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this  # earthquake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask .  Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to  ' shelter in place '  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive  # wildfires evacuation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby  # Alaska a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  target_relabeled                                       text_cleaned  \n",
       "0       1                 1  Our Deeds are the Reason of this  # earthquake...  \n",
       "1       1                 1           Forest fire near La Ronge Sask .  Canada  \n",
       "2       1                 1  All residents asked to  ' shelter in place '  ...  \n",
       "3       1                 1  13,000 people receive  # wildfires evacuation ...  \n",
       "4       1                 1  Just got sent this photo from Ruby  # Alaska a...  "
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of DistilBERT (lighter version of BERT) for approaching Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22cab069a9c402f8dc4f81e5626073a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9373ee7d574ae49c0cc8a4c535f1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6283941c75f44c18fafbbc147005633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model/tokenizer for DistilBERT:\n",
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = transformers.DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_classifier(text, column = None):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "        \n",
    "        text: may be either a DataFrame (containing multiple tweets) or a string (single tweet)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Tokenization ###\n",
    "    if ((isinstance(text, pd.DataFrame)) | (isinstance(text, pd.Series)))\\\n",
    "        & (column is not None):\n",
    "        \n",
    "        tokenized = text[column].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "        \n",
    "    elif isinstance(text, str):\n",
    "        \n",
    "        tokenized = tokenizer.encode(text, add_special_tokens=True)\n",
    "        tokenized = pd.Series([tokenized])  \n",
    "    else:\n",
    "        print('NOT RECOGNIZED DATA TYPE')\n",
    "    \n",
    "    # Output of tokenization is a pd.Series, with len equal to the number of tweets.\n",
    "    # Each element of the series is a list which contains the tokenized tweet.\n",
    "    \n",
    "    \n",
    "    ### Padding ###\n",
    "    max_len = tokenized.apply(lambda x: len(x)).max()\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "    \n",
    "    \n",
    "    ### Masking ###\n",
    "    attention_mask = np.where(padded != 0 , 1, 0)\n",
    "    attention_mask.shape\n",
    "    \n",
    "    # This mask contains 1 where values of the padded tokenized series is different from 0 (i.e. where no padding was applied)\n",
    "    # and 0 elsewhere.\n",
    "    \n",
    "    \n",
    "    ### Features extraction ###\n",
    "    input_ids = torch.LongTensor(padded) #.tensor(padded)\n",
    "    attention_mask = torch.LongTensor(attention_mask) #.tensor(attention_mask)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids, attention_mask = attention_mask) # very long computation!!!\n",
    "    \n",
    "    features = last_hidden_states[0][:,0,:].numpy()\n",
    "    \n",
    "    # [:,0,:] -> allows to take only the features devoted to a classification task\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_FE:\n",
    "    # Extract features for classification (very heavy computation!!!)\n",
    "    features = prepare_for_classifier(df_train, 'text_cleaned')\n",
    "\n",
    "    # Save to pickle\n",
    "    with open('features.pkl', 'wb') as handle:\n",
    "        pickle.dump(features, handle, protocol = 4)\n",
    "\n",
    "else:\n",
    "    # Import pickle with features\n",
    "    with open('features.pkl', 'rb') as handle:\n",
    "        features = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derived features are used in order to train a series of classification models, which are finally ensembled by a stacking classifier (Supervised Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_train['target_relabeled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Train: (5709, 768)\n",
      "Target Train: (5709,)\n",
      "\n",
      "Features Test: (1904, 768)\n",
      "Target Test: (1904,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features Train: {X_train.shape}\")\n",
    "print(f\"Target Train: {y_train.shape}\\n\")\n",
    "\n",
    "print(f\"Features Test: {X_test.shape}\")\n",
    "print(f\"Target Test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'bootstrap': [True],\n",
    "    'ccp_alpha': [0.01, 0.001],\n",
    "    'criterion': [\"entropy\"],\n",
    "    'max_depth': [5,6,7,8,9,10],\n",
    "    'max_features': [70],\n",
    "    'min_samples_leaf': [1],\n",
    "    'min_samples_split': [2],\n",
    "    'class_weight': ['balanced'],\n",
    "    'n_estimators': [100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(model_rf, parameters, cv=3, scoring = 'f1', verbose=10, n_jobs=-1, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   51.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   51.3s finished\n"
     ]
    }
   ],
   "source": [
    "gs = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** GRIDSEARCH RESULTS **\n",
      "Best score: 0.7275985008312129 using {'bootstrap': True, 'ccp_alpha': 0.01, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 10, 'max_features': 60, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"** GRIDSEARCH RESULTS **\")\n",
    "print(f\"Best score: {gs.best_score_} using {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gs.best_estimator_\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** F1 Score **\n",
      "Train: 0.74\n",
      "Test: 0.72\n",
      "\n",
      "** Accuracy **\n",
      "Baseline - all zeroes: 0.57\n",
      "Train: 0.79\n",
      "Test: 0.78\n"
     ]
    }
   ],
   "source": [
    "print(f\"** F1 Score **\")\n",
    "print(f\"Train: {f1_score(y_train, y_pred_train):0.2f}\")\n",
    "print(f\"Test: {f1_score(y_test, y_pred_test):0.2f}\\n\")\n",
    "\n",
    "print(f\"** Accuracy **\")\n",
    "print(f\"Baseline - all zeroes: {accuracy_score(y_test, np.zeros(y_test.shape[0])):0.2f}\")\n",
    "print(f\"Train: {accuracy_score(y_train, y_pred_train):0.2f}\")\n",
    "print(f\"Test: {accuracy_score(y_test, y_pred_test):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = X_train\n",
    "xgb_val = X_test[:952]\n",
    "xgb_test = X_test[952:]\n",
    "\n",
    "xgb_y_train = y_train\n",
    "xgb_y_validation = y_test[:952]\n",
    "xgb_y_test = y_test[952:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.21300\tvalidation_1-error:0.25735\n",
      "Multiple eval metrics have been passed: 'validation_1-error' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-error hasn't improved in 200 rounds.\n",
      "[20]\tvalidation_0-error:0.13558\tvalidation_1-error:0.20168\n",
      "[40]\tvalidation_0-error:0.10194\tvalidation_1-error:0.19748\n",
      "[60]\tvalidation_0-error:0.07637\tvalidation_1-error:0.19958\n",
      "[80]\tvalidation_0-error:0.05027\tvalidation_1-error:0.19013\n",
      "[100]\tvalidation_0-error:0.03678\tvalidation_1-error:0.17752\n",
      "[120]\tvalidation_0-error:0.02470\tvalidation_1-error:0.18698\n",
      "[139]\tvalidation_0-error:0.01822\tvalidation_1-error:0.18802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1.0, gamma=0.2, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=140, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=42, reg_alpha=0.1,\n",
       "              reg_lambda=0.3, scale_pos_weight=1, seed=42, subsample=0.6,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(learning_rate=0.1,\n",
    "                          n_estimators=140,\n",
    "                          max_depth=5,\n",
    "                          reg_alpha=0.1,\n",
    "                          reg_lambda=0.3,\n",
    "                          min_child_weight=3,\n",
    "                          gamma=0.2,\n",
    "                          subsample=0.6,\n",
    "                          colsample_bytree=1.0,\n",
    "                          objective='binary:logistic',\n",
    "                          nthread=4,\n",
    "                          scale_pos_weight=1,\n",
    "                          seed=42)\n",
    "xgb_model.fit(xgb_train, \n",
    "              xgb_y_train,\n",
    "              eval_set=[(xgb_train, xgb_y_train), (xgb_val, xgb_y_validation)], \n",
    "              verbose=20, \n",
    "              early_stopping_rounds=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train_pred = xgb_model.predict(xgb_train)\n",
    "xgb_val_pred = xgb_model.predict(xgb_val)\n",
    "xgb_test_pred = xgb_model.predict(xgb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> XGB Model:\n",
      "Train f1: 0.9560669456066946\n",
      "Validation f1: 0.7773386034255599\n",
      "Test f1: 0.7643979057591624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'>>> XGB Model:')\n",
    "print(f'Train f1: {f1_score(xgb_y_train, xgb_train_pred)}')\n",
    "print(f'Validation f1: {f1_score(xgb_y_validation, xgb_val_pred)}')\n",
    "print(f'Test f1: {f1_score(xgb_y_test, xgb_test_pred)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_clf = RidgeClassifier()\n",
    "ridge_params = {'alpha': np.arange(7,15),\n",
    "                'class_weight': [None],\n",
    "                'copy_X': [True],\n",
    "                'fit_intercept': [True],\n",
    "                'max_iter': [None],\n",
    "                'normalize': [False],\n",
    "                'random_state': [42],\n",
    "                'solver': ['auto'],\n",
    "                'tol': [0.001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_gs = GridSearchCV(ridge_clf, ridge_params, cv=10, scoring = 'f1', verbose=10, n_jobs=-1, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   17.2s finished\n"
     ]
    }
   ],
   "source": [
    "ridge_gs = ridge_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** GRIDSEARCH RESULTS **\n",
      "Best score: 0.7678875580941108 using {'alpha': 9, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print(\"** GRIDSEARCH RESULTS **\")\n",
    "print(f\"Best score: {ridge_gs.best_score_} using {ridge_gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ridge = ridge_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = best_ridge.predict(X_train)\n",
    "y_pred_test = best_ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** F1 Score **\n",
      "Train: 0.807\n",
      "Test: 0.775\n",
      "\n",
      "** Accuracy **\n",
      "Baseline - all zeroes: 0.574\n",
      "Train: 0.847\n",
      "Test: 0.820\n"
     ]
    }
   ],
   "source": [
    "print(f\"** F1 Score **\")\n",
    "print(f\"Train: {f1_score(y_train, y_pred_train):0.3f}\")\n",
    "print(f\"Test: {f1_score(y_test, y_pred_test):0.3f}\\n\")\n",
    "\n",
    "print(f\"** Accuracy **\")\n",
    "print(f\"Baseline - all zeroes: {accuracy_score(y_test, np.zeros(y_test.shape[0])):0.3f}\")\n",
    "print(f\"Train: {accuracy_score(y_train, y_pred_train):0.3f}\")\n",
    "print(f\"Test: {accuracy_score(y_test, y_pred_test):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = gnb_clf.predict(X_train)\n",
    "y_pred_test = gnb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** F1 Score **\n",
      "Train: 0.696\n",
      "Test: 0.715\n",
      "\n",
      "** Accuracy **\n",
      "Baseline - all zeroes: 0.574\n",
      "Train: 0.751\n",
      "Test: 0.767\n"
     ]
    }
   ],
   "source": [
    "print(f\"** F1 Score **\")\n",
    "print(f\"Train: {f1_score(y_train, y_pred_train):0.3f}\")\n",
    "print(f\"Test: {f1_score(y_test, y_pred_test):0.3f}\\n\")\n",
    "\n",
    "print(f\"** Accuracy **\")\n",
    "print(f\"Baseline - all zeroes: {accuracy_score(y_test, np.zeros(y_test.shape[0])):0.3f}\")\n",
    "print(f\"Train: {accuracy_score(y_train, y_pred_train):0.3f}\")\n",
    "print(f\"Test: {accuracy_score(y_test, y_pred_test):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf = SVC()\n",
    "svc_params = {'C': [0.001, 0.01, 0.1, 1],\n",
    "              'class_weight': [None],\n",
    "              'coef0': [0.0],\n",
    "              'degree': [3],\n",
    "              'gamma': ['scale'],\n",
    "              'kernel': ['rbf', 'linear'],\n",
    "              'max_iter': [-1],\n",
    "              'probability': [False],\n",
    "              'random_state': [42],\n",
    "              'shrinking': [True],\n",
    "              'tol': [0.001],\n",
    "              'verbose': [False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_gs = GridSearchCV(svc_clf, svc_params, cv=3, scoring = 'f1', verbose=10, n_jobs=-1, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  24 | elapsed:  4.1min remaining:   49.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  4.5min finished\n"
     ]
    }
   ],
   "source": [
    "svc_gs = svc_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** GRIDSEARCH RESULTS **\n",
      "Best score: 0.7603890665338128 using {'C': 0.1, 'class_weight': None, 'coef0': 0.0, 'degree': 3, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "print(\"** GRIDSEARCH RESULTS **\")\n",
    "print(f\"Best score: {svc_gs.best_score_} using {svc_gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svc = svc_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = best_svc.predict(X_train)\n",
    "y_pred_test = best_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** F1 Score **\n",
      "Train: 0.801\n",
      "Test: 0.781\n",
      "\n",
      "** Accuracy **\n",
      "Baseline - all zeroes: 0.574\n",
      "Train: 0.844\n",
      "Test: 0.828\n"
     ]
    }
   ],
   "source": [
    "print(f\"** F1 Score **\")\n",
    "print(f\"Train: {f1_score(y_train, y_pred_train):0.3f}\")\n",
    "print(f\"Test: {f1_score(y_test, y_pred_test):0.3f}\\n\")\n",
    "\n",
    "print(f\"** Accuracy **\")\n",
    "print(f\"Baseline - all zeroes: {accuracy_score(y_test, np.zeros(y_test.shape[0])):0.3f}\")\n",
    "print(f\"Train: {accuracy_score(y_train, y_pred_train):0.3f}\")\n",
    "print(f\"Test: {accuracy_score(y_test, y_pred_test):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble - Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('ridge', best_ridge),\n",
    "    ('gnb', gnb_clf),\n",
    "    ('svc', best_svc)\n",
    "]\n",
    "stacking = StackingClassifier(estimators=estimators,\n",
    "                              final_estimator=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=None,\n",
       "                   estimators=[('ridge',\n",
       "                                RidgeClassifier(alpha=9, class_weight=None,\n",
       "                                                copy_X=True, fit_intercept=True,\n",
       "                                                max_iter=None, normalize=False,\n",
       "                                                random_state=42, solver='auto',\n",
       "                                                tol=0.001)),\n",
       "                               ('gnb',\n",
       "                                GaussianNB(priors=None, var_smoothing=1e-09)),\n",
       "                               ('svc',\n",
       "                                SVC(C=0.1, break_ties=False, cache_size=200,\n",
       "                                    class_weight=None, coef0=0.0,\n",
       "                                    decision_function_shape='ovr...\n",
       "                                    shrinking=True, tol=0.001,\n",
       "                                    verbose=False))],\n",
       "                   final_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                      dual=False,\n",
       "                                                      fit_intercept=True,\n",
       "                                                      intercept_scaling=1,\n",
       "                                                      l1_ratio=None,\n",
       "                                                      max_iter=100,\n",
       "                                                      multi_class='auto',\n",
       "                                                      n_jobs=None, penalty='l2',\n",
       "                                                      random_state=None,\n",
       "                                                      solver='lbfgs',\n",
       "                                                      tol=0.0001, verbose=0,\n",
       "                                                      warm_start=False),\n",
       "                   n_jobs=None, passthrough=False, stack_method='auto',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = stacking.predict(X_train)\n",
    "y_pred_test = stacking.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** F1 Score **\n",
      "Train: 0.81\n",
      "Test: 0.79\n",
      "\n",
      "** Accuracy **\n",
      "Baseline - all zeroes: 0.57\n",
      "Train: 0.85\n",
      "Test: 0.83\n"
     ]
    }
   ],
   "source": [
    "print(f\"** F1 Score **\")\n",
    "print(f\"Train: {f1_score(y_train, y_pred_train):0.2f}\")\n",
    "print(f\"Test: {f1_score(y_test, y_pred_test):0.2f}\\n\")\n",
    "\n",
    "print(f\"** Accuracy **\")\n",
    "print(f\"Baseline - all zeroes: {accuracy_score(y_test, np.zeros(y_test.shape[0])):0.2f}\")\n",
    "print(f\"Train: {accuracy_score(y_train, y_pred_train):0.2f}\")\n",
    "print(f\"Test: {accuracy_score(y_test, y_pred_test):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stacking_model.pkl', 'wb') as handle:\n",
    "    pickle.dump(stacking, handle, protocol = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}